{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UKOQcXNtJ8e"
   },
   "source": [
    "# TDA233 / DIT382 Machine Learning: Homework 1 <br />\n",
    "**Goal:** Start working with Jupyter notebooks, introduction to probability and regression models <br />\n",
    "**Grader:** Jack Sandberg <br />\n",
    "**Submitted by:** üìù Pontus Strandvik, 19920613-2590, pontus.strandvik@hotmail.se and William Sn√§ll, 199903291830, snallw@chalmers.se <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQ8gZxqWtJ8h"
   },
   "source": [
    "# Read this before starting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## General guidelines\n",
    "* Answer all fields marked with üìù (and `# TODO` in the code blocks). This includes\n",
    "    * your name, personal number and email address above, and\n",
    "    * all later fields marked with \"üìù Your answer here:\".\n",
    "* Feel free to add more cells if needed.\n",
    "* All solutions to theoretical and pratical problems must be submitted in this notebook, and equations wherever required, should be formatted using LaTeX math-mode.\n",
    "    * Do NOT hand in an assignment that isn't runnable!\n",
    "* All discussion regarding practical problems, along with solutions and plots should be specified in this notebook. \n",
    "All plots/results should be visible such that the notebook does not have to be run. But the code in the notebook should reproduce the plots/results if we choose to do so.\n",
    "* All tables and other additional information should be included in this notebook.\n",
    "* **Before submitting, make sure that your code can run on another computer, i.e. that all plots can show on another computer including all your text and equations. It is good to check if your code can run here: https://colab.research.google.com**\n",
    "* **Submit your solutions as a notebook file (`.ipynb`) and in HTML format (`.html`). To export this notebook to HTML format click `File` $\\rightarrow$ `Download as` $\\rightarrow$ `HTML`.**\n",
    "\n",
    "**Jupyter/IPython Notebook** is a collaborative Python web-based environment. This will be used in all our Homework Assignments. It is installed in the halls ES61-ES62, E-studio and MT9. You can also use google-colab: https://colab.research.google.com\n",
    "to run these notebooks without having to download, install, or do anything on your own computer other than a browser.\n",
    "Some useful resources:\n",
    "1. https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/ (Quick-start guide)\n",
    "2. https://www.kdnuggets.com/2016/04/top-10-ipython-nb-tutorials.html\n",
    "3. http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required software\n",
    "\n",
    "For the practical problem in this assignment you will need to install the following Python packages:\n",
    "\n",
    "- `numpy`: The fundamental package for scientific computing with Python (so fundamental there is a [Nature review](https://www.nature.com/articles/s41586-020-2649-2) on it)\n",
    "- `matplotlib`: Visualization with Python\n",
    "- `sklearn`: Scikit-learn is a package for performing machine learning in Python.\n",
    "\n",
    "> **Note:** In Google Colab you can install packages using   `!pip  install <package_name>`\n",
    "\n",
    "> **Note:** In Google Colab these packages should be preinstalled but it is a good habit to check if all required packages are installed beforehand and the installed versions of packages. Use `!pip list` to list packages installed by pip on Google Colab.\n",
    "\n",
    "> **Note:** We recommend that you install these packages in a [virtual environment](https://docs.python.org/3/library/venv.html) if you are running this on your own computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl1Lu21rtJ8k"
   },
   "source": [
    "# Part 1: Theoretical problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Bayes Rule [3 points]\n",
    "\n",
    "After your yearly checkup, the doctor has bad news and good news. The\n",
    "bad news is that you tested positive for a very serious cancer and\n",
    "that the test is 99.5% accurate i.e. the probability of testing\n",
    "positive given you have the disease is 0.995. The probability of\n",
    "testing negative if you don‚Äôt have the disease is the same (also 0.995). The good news is that it is a rare condition affecting only 1 in 500 people. **What is the probability you actually have the disease?** \n",
    "\n",
    "After doing all your calculations you realize that there was a misprint on the test, and the accuracy was actually only 95% (for both testing postive given that you have the disease and for testing negative given that you do not have the disease). **How will this change your probability of having the disease?**\n",
    "\n",
    "Show all calculations and the final result. Remember to use LaTeX math-mode to format mathematical expressions and equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Define the variables:\n",
    "- \\( X = 1 \\): The event of having the disease.\n",
    "- \\( X = 0 \\): The event of not having the disease.\n",
    "- \\( Y = 1 \\): The event of testing positive.\n",
    "- \\( Y = 0 \\): The event of testing negative.\n",
    "\n",
    "Known probabilities:\n",
    "- The prevalence of the disease:\n",
    "$\n",
    "P(X = 1) = \\frac{1}{500} = 0.002\n",
    "$\n",
    "$\n",
    "P(X = 0) = 1 - P(X = 1) = 0.998\n",
    "$\n",
    "\n",
    "Case 1: Test accuracy 99.5%\n",
    "$\n",
    "P(Y = 1 \\mid X = 1) = 0.995, \\quad P(Y = 0 \\mid X = 0) = 0.995\n",
    "$\n",
    "$\n",
    "P(Y = 0 \\mid X = 1) = 1 - P(Y = 1 \\mid X = 1) = 0.005, \\quad P(Y = 1 \\mid X = 0) = 1 - P(Y = 0 \\mid X = 0) = 0.005\n",
    "$\n",
    "\n",
    "Case 2: Test accuracy 95%\n",
    "$\n",
    "P(Y = 1 \\mid X = 1) = 0.95, \\quad P(Y = 0 \\mid X = 0) = 0.95\n",
    "$\n",
    "$\n",
    "P(Y = 0 \\mid X = 1) = 1 - P(Y = 1 \\mid X = 1) = 0.05, \\quad P(Y = 1 \\mid X = 0) = 1 - P(Y = 0 \\mid X = 0) = 0.05\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Bayes' Theorem:\n",
    "Bayes' Theorem calculates the probability of having the disease given a positive test result:\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{P(Y = 1 \\mid X = 1) P(X = 1)}{P(Y = 1)}\n",
    "$\n",
    "where:\n",
    "$\n",
    "P(Y = 1) = P(Y = 1 \\mid X = 1) P(X = 1) + P(Y = 1 \\mid X = 0) P(X = 0)\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "-Case 1: Test accuracy 99.5%\n",
    "1. Calculate \\( P(Y = 1) \\):\n",
    "$\n",
    "P(Y = 1) = P(Y = 1 \\mid X = 1) P(X = 1) + P(Y = 1 \\mid X = 0) P(X = 0)\n",
    "$\n",
    "$\n",
    "P(Y = 1) = (0.995)(0.002) + (0.005)(0.998)\n",
    "$\n",
    "$\n",
    "P(Y = 1) = 0.00199 + 0.00499 = 0.00698\n",
    "$\n",
    "\n",
    "2. Calculate \\( P(X = 1 \\mid Y = 1) \\):\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{P(Y = 1 \\mid X = 1) P(X = 1)}{P(Y = 1)}\n",
    "$\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{(0.995)(0.002)}{0.00698}\n",
    "$\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{0.00199}{0.00698} \\approx 0.285\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Case 2: Test accuracy 95%\n",
    "1. Calculate $ P(Y = 1)$: \n",
    "$\n",
    "P(Y = 1) = P(Y = 1 \\mid X = 1) P(X = 1) + P(Y = 1 \\mid X = 0) P(X = 0)\n",
    "$\n",
    "$\n",
    "P(Y = 1) = (0.95)(0.002) + (0.05)(0.998)\n",
    "$\n",
    "$\n",
    "P(Y = 1) = 0.0019 + 0.0499 = 0.0518\n",
    "$\n",
    "\n",
    "2. Calculate $ P(X = 1 \\mid Y = 1)$ :\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{P(Y = 1 \\mid X = 1) P(X = 1)}{P(Y = 1)}\n",
    "$\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{(0.95)(0.002)}{0.0518}\n",
    "$\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) = \\frac{0.0019}{0.0518} \\approx 0.037\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Finally: \n",
    "1. When the test accuracy is **99.5%**, the probability of having the disease given a positive test result is:\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) \\approx 28.5\\%\n",
    "$\n",
    "\n",
    "2. When the test accuracy is **95%**, the probability of having the disease given a positive test result decreases to:\n",
    "$\n",
    "P(X = 1 \\mid Y = 1) \\approx 3.7\\%\n",
    "$\n",
    "\n",
    "Thus, the lower test accuracy significantly reduces the probability of actually having the disease after testing positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Setting hyperparameters [2 points]\n",
    "\n",
    "Suppose $\\theta$ is a random variable generated from a beta distribution as: $\\theta \\sim \\text{Beta}(a^2,b)$. Also assume that  the expectation of $\\theta$ is $m$: $E[\\theta] = m$\n",
    "and the variance of $\\theta$ is $v$: $\\text{Var}(\\theta) = v$. Express $a$ and $b$ in terms of (only) $m$ and $v$.\n",
    "For more information about the $\\text{Beta}$ distribution see https://en.wikipedia.org/wiki/Beta_distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the properties of the Beta distribution  \n",
    "For $\\theta \\sim \\text{Beta}(a^2, b)$, the following properties hold:\n",
    "1. The expectation is:\n",
    "   $\n",
    "   E[\\theta] = \\frac{a^2}{a^2 + b} = m\n",
    "   $\n",
    "2. The variance is:\n",
    "   $\n",
    "   \\text{Var}(\\theta) = \\frac{a^2 b}{(a^2 + b)^2 (a^2 + b + 1)} = v\n",
    "   $\n",
    "\n",
    "\n",
    "\n",
    "Step 2: Express $b$ in terms of $a^2$ and $m$  \n",
    "From the expectation:\n",
    "$\n",
    "m = \\frac{a^2}{a^2 + b}\n",
    "$\n",
    "Rearranging for $b$:\n",
    "$\n",
    "b = \\frac{a^2 (1 - m)}{m}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Step 3: Substitute $b$ into the variance equation  \n",
    "The variance is:\n",
    "$\n",
    "v = \\frac{a^2 b}{(a^2 + b)^2 (a^2 + b + 1)}\n",
    "$\n",
    "Substitute $b = \\frac{a^2 (1 - m)}{m}$:\n",
    "$\n",
    "v = \\frac{a^2 \\cdot \\frac{a^2 (1 - m)}{m}}{\\left(a^2 + \\frac{a^2 (1 - m)}{m}\\right)^2 \\left(a^2 + \\frac{a^2 (1 - m)}{m} + 1\\right)}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Step 4: Simplify the terms  \n",
    "1. Combine $a^2 + b$:\n",
    "   $\n",
    "   a^2 + b = a^2 + \\frac{a^2 (1 - m)}{m} = \\frac{a^2}{m}\n",
    "   $\n",
    "2. Combine $a^2 + b + 1$:\n",
    "   $\n",
    "   a^2 + b + 1 = \\frac{a^2}{m} + 1\n",
    "   $\n",
    "Substituting these into the variance equation:\n",
    "$\n",
    "v = \\frac{a^4 (1 - m)}{m \\cdot \\left(\\frac{a^2}{m}\\right)^2 \\cdot \\left(\\frac{a^2}{m} + 1\\right)}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Step 5: Simplify further  \n",
    "1. Simplify $\\left(\\frac{a^2}{m}\\right)^2$:\n",
    "   $\n",
    "   \\left(\\frac{a^2}{m}\\right)^2 = \\frac{a^4}{m^2}\n",
    "   $\n",
    "2. Substitute into the variance:\n",
    "   $\n",
    "   v = \\frac{a^4 (1 - m)}{m \\cdot \\frac{a^4}{m^2} \\cdot \\left(\\frac{a^2}{m} + 1\\right)}\n",
    "   $\n",
    "   $\n",
    "   v = \\frac{a^4 (1 - m) m^2}{m a^4 \\left(\\frac{a^2}{m} + 1\\right)}\n",
    "   $\n",
    "Cancel $a^4$:\n",
    "$\n",
    "v = \\frac{(1 - m) m^2}{\\frac{a^2}{m} + 1}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Step 6: Solve for $a^2$  \n",
    "Rearrange to isolate $a^2$:\n",
    "$\n",
    "\\frac{(1 - m) m^2}{v} = \\frac{a^2}{m} + 1\n",
    "$\n",
    "$\n",
    "\\frac{(1 - m) m^2}{v} - 1 = \\frac{a^2}{m}\n",
    "$\n",
    "$\n",
    "a^2 = m \\left(\\frac{(1 - m) m^2}{v} - 1\\right)\n",
    "$\n",
    "\n",
    "\n",
    "Step 7: Solve for $b$  \n",
    "Using $b = \\frac{a^2 (1 - m)}{m}$, substitute $a^2$:\n",
    "$\n",
    "b = \\frac{m \\left(\\frac{(1 - m) m^2}{v} - 1\\right) (1 - m)}{m}\n",
    "$\n",
    "$\n",
    "b = \\left(\\frac{(1 - m) m^2}{v} - 1\\right)(1 - m)\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "Final Result  \n",
    "The parameters $a$ and $b$ are expressed as:\n",
    "1. $a$:\n",
    "   $\n",
    "   a = \\sqrt{m \\left(\\frac{(1 - m) m^2}{v} - 1\\right)}\n",
    "   $\n",
    "2. $b$:\n",
    "   $\n",
    "   b = \\left(\\frac{(1 - m) m^2}{v} - 1\\right)(1 - m)\n",
    "   $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Correlation and Independence [2 points]\n",
    "\n",
    "Let $X$ be a continuous random variable, uniformly distributed in $[-2, +2]$ and let $Y := X^4$. Clearly $Y$ is not independent of $X$ -- in fact it is uniquely determined by $X$. However, show that the covariance of $X$ and $Y$ is 0: $\\text{cov}(X, Y ) = 0$.\n",
    "Show and justify every step of the proof. Statements like \"it is obvious that, it is trivial ...\" will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here: \n",
    "\n",
    "We know that COV(X, Y) = $E[(X - x_\\mu)(Y - y_\\mu)]$. $\\newline$  $x_\\mu = E[X] = \\int_{a}^{b} xp(x) \\, dx$. p(x) for x is uniform and has the form $\\frac{1}{b-a}$ wich evaluates to $\\frac{1}{4}$. So $\\int_{a}^{b} xp(x) \\, dx$ evaluates to $\\int_{-2}^{2} x \\frac{1}{4} \\, dx = \\frac{1}{4}\\left[\\frac{x^2}{2}\\right]_{-2}^{2} = \\frac{1}{4}(\\frac{4}{2} - \\frac{4}{2}).$ $\\newline$ Doing the same thing for $y_\\mu$ we get $y_\\mu = E[Y] = E[X^4] = \\int_{-2}^{2} x^4 \\frac{1}{4} = \\frac{1}{4}\\left[\\frac{x^5}{5}\\right]_{-2}^{2} = \\frac{1}{4}(\\frac{32}{5} - (-\\frac{32}{5})) = \\frac{64}{20} = \\frac{16}{5} $ $\\newline$ \n",
    "Now we can evaluate $E[(X - x_\\mu)(Y - y_\\mu)]$ $\\newline$\n",
    "COV(X,Y) = $E[(x - 0)(x^4 - \\frac{16}{5})] = E[(x^5 - \\frac{16x}{5})] = \\frac{1}{4}\\int_{-2}^{2} (x^5  - \\frac{16x}{5}) \\, dx = \\frac{1}{4}\\left[\\frac{x^6}{6} -\\frac{16x^2}{10}\\right]_{-2}^{2} = \\frac{1}{4}((\\frac{64}{6} - \\frac{64}{10})-(\\frac{64}{6} - \\frac{64}{10})) = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Spherical Gaussian estimation [4 points]\n",
    "\n",
    "Consider a dataset $X$ consisting of i.i.d. observations\n",
    "generated from a spherical Gaussian distribution $N(\\mu, \\sigma^2I)$, where $\\mu \\in \\mathbb{R}^p$, $I$ \n",
    "is the $p \\times p $ identity matrix, and $\\sigma^2$ is a scalar.\n",
    "\n",
    "Write the mathematical expression for the Maximum Likelihood Estimator (MLE) for $\\mu$ and $\\sigma$ in above setup.\n",
    "\n",
    "For more information about the spherical Gaussian distribution, see https://en.wikipedia.org/wiki/Multivariate_normal_distribution.\n",
    "For more information about the identity matrix see: https://en.wikipedia.org/wiki/Identity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the dataset $X = \\{x_1, x_2, \\dots, x_n\\}$, where $x_i \\in \\mathbb{R}^p$, the probability density function of a spherical Gaussian distribution is:\n",
    "\n",
    "$$\n",
    "p(x_i | \\mu, \\sigma^2) = \\frac{1}{(2\\pi \\sigma^2)^{p/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} \\|x_i - \\mu\\|^2\\right)\n",
    "$$\n",
    "\n",
    "where the squared Euclidean norm is defined as:\n",
    "\n",
    "$$\n",
    "\\|x_i - \\mu\\|^2 = (x_i - \\mu)^\\top (x_i - \\mu).\n",
    "$$\n",
    "\n",
    "The log-likelihood function for the dataset $X$ is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mu, \\sigma^2) = \\sum_{i=1}^n \\log p(x_i | \\mu, \\sigma^2).\n",
    "$$\n",
    "\n",
    "Substituting the probability density function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mu, \\sigma^2) = -\\frac{np}{2} \\log(2\\pi) - \\frac{np}{2} \\log \\sigma^2 - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n \\|x_i - \\mu\\|^2.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "MLE for $\\mu$:\n",
    "\n",
    "To determine the maximum likelihood estimator for $\\mu$, we differentiate $\\mathcal{L}(\\mu, \\sigma^2)$ with respect to $\\mu$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mu} = -\\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu).\n",
    "$$\n",
    "\n",
    "Setting the derivative to zero:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (x_i - \\mu) = 0 \\quad \\implies \\quad \\mu = \\frac{1}{n} \\sum_{i=1}^n x_i.\n",
    "$$\n",
    "\n",
    "**MLE for $\\mu$:**\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "MLE for $\\sigma^2$\n",
    "\n",
    "Next, we compute the derivative of $\\mathcal{L}(\\mu, \\sigma^2)$ with respect to $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\sigma^2} = -\\frac{np}{2\\sigma^2} + \\frac{1}{2\\sigma^4} \\sum_{i=1}^n \\|x_i - \\mu\\|^2.\n",
    "$$\n",
    "\n",
    "Setting this derivative equal to zero:\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{np} \\sum_{i=1}^n \\|x_i - \\mu\\|^2.\n",
    "$$\n",
    "\n",
    "By substituting $\\hat{\\mu}$ in place of $\\mu$, the MLE for $\\sigma^2$ is:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{np} \\sum_{i=1}^n \\|x_i - \\hat{\\mu}\\|^2.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Finally:\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n x_i,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{np} \\sum_{i=1}^n \\|x_i - \\hat{\\mu}\\|^2.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma} = \\sqrt{\\frac{1}{np} \\sum_{i=1}^n \\|x_i - \\hat{\\mu}\\|^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Practical problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Linear Regression with regularization [9 points]\n",
    "\n",
    "You are newly recruited as a Data Scientist at a leading consultancy company in Gothenburg. Your first task at the job is to help the Swedish Public Health Agency (folkh√§lsomyndigheten) for predicting the diabetes progression of patients. Assume that you are given a dataset D of $n$ patients with $D = \\{ (\\mathbf{x}_i, y_i)\\}_{i=1}^n$ where $\\mathbf{x}_i \\in \\mathbb{R}^p$ represents numerical features of each patients and $y_i \\in \\mathbb{R}$ represent the numerical diabetes progression.  One can also view the dataset D as a pair of matrices $(\\mathbf{X}, \\mathbf{y})$ with $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and $\\mathbf{y} \\in \\mathbb{R}^{n \\times 1}$.\n",
    "\n",
    "Fresh with the lectures in the machine learning course at Chalmers, you would like to use a linear model to quickly perform the task. In order words, you would like to find a vector $\\mathbf{w} \\in \\mathbb{R}^{p \\times 1}$  such that $\\mathbf{y} = \\mathbf{X} \\mathbf{w}$.  However,  you have just read one of the most popular machine learning books and it argues that standard linear regression (for finding $\\mathbf{w}$) can lead to various problems such as non-uniqueness of the solution,  overfitting, etc. As a result, you decided to add a penalty term called regularization to control the optimisation problem. More specifically, you want to solve for: $\\min_{\\mathbf{w}}  \\mathcal{L}(\\mathbf{w})$ where  $\\mathcal{L}(\\mathbf{w}) = \\left(\\sum_{i=1}^n (y_i - \\mathbf{w}^T\\mathbf{x}_i)^2 \\right) + \\left(\\alpha \\sum_{j=1}^p w_j^2 \\right) $ with $\\alpha \\in \\mathbb{R}$ a small coefficient that you will decide later on.\n",
    "\n",
    "Please note the slight changes in the notation. Recall that in the lectures we had a dataset $\\{ (\\mathbf{x}_n, t_n)\\}_{n=1}^N$ where $\\mathbf{x}_n \\in \\mathbb{R}^D$ and $t_n \\in \\mathbb{R}$. We also appended $1$ to the begining of $\\mathbf{x}_n$ so both $\\mathbf{x}_n$ and $\\mathbf{w}$ were in $\\mathbb{R}^{D+1}$. Thus, here $p$ is the same thing as $D+1$. Compare $w_1, w_2, \\dots, w_p$ with $w_0, w_1, \\dots, w_D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Expression for loss function [1 point]\n",
    "Write down $\\mathcal{L}(\\mathbf{w})$ in matrix/vector forms using only $\\mathbf{X}$, $\\mathbf{y}$ and $\\mathbf{w}$ and the L2 norm. In other words, you are not allowed to use any components $y_i, \\mathbf{w}_j$ or $\\mathbf{x}_i$ ( For any vector $\\mathbf{z}$ use the following notation $|\\mathbf{z}|_2$ to mean the L2 norm of  $\\mathbf{z}$ See http://mathworld.wolfram.com/L2-Norm.html for more information about the L2 norm.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here:\n",
    "\n",
    "$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}((\\mathbf{y} - \\mathbf{Xw})^T(\\mathbf{y} - \\mathbf{Xw}) + a \\,\\mathbf{w^Tw})$\n",
    "\n",
    "or with the $l^2$-norm\n",
    "\n",
    "$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}((|\\mathbf{y} - \\mathbf{Xw}|^2_2) + a \\,|\\mathbf{w^Tw}|^2_2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Gradient of loss function [1 point] \n",
    "Derive and write down in matrix/vector forms the gradient of $\\mathcal{L}(\\mathbf{w})$ with respect to $\\mathbf{w}$. Show all the derivations. (Hint: You can start by  computing the gradient of the full expression and then convert it to matrix/vector forms. You can also directly get the gradients from your answer in a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here:\n",
    "\n",
    "\n",
    "\n",
    "#### Step 1: apply rule of transponents \n",
    "The rule is that (a + b)^T = a^T + b^t  \n",
    "so the expression $\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}((\\mathbf{y} - \\mathbf{Xw})^T(\\mathbf{y} - \\mathbf{Xw}) + a \\,\\mathbf{w^Tw})$ becomes: \n",
    "\n",
    "$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}((\\mathbf{y}^T - \\mathbf{Xw}^T)(\\mathbf{y} - \\mathbf{Xw}) + a \\,\\mathbf{w^Tw})$\n",
    "\n",
    "#### Step 2: Multiply out the factors\n",
    "$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{y}^T \\mathbf{y} - \\mathbf{y}^T \\mathbf{Xw} - \\mathbf{(Xw)}^T \\mathbf{y} + \\mathbf{(Xw)}^T \\mathbf{Xw} + a \\,\\mathbf{w^Tw})$\n",
    "\n",
    "#### Step 3: Recognize that $\\mathbf{y}^T \\mathbf{Xw} = \\mathbf{(Xw)}^T \\mathbf{y}$\n",
    "By applying the rules of transponents we get that $\\mathbf{y}^T \\mathbf{(Xw)}$  evaluates to $(\\mathbf{(Xw)}^T \\mathbf{y})^T$. We also know that $\\mathbf{(Xw)}^T \\mathbf{y}$ is a scalar and a transpose of a scalar does not change it so therefore $\\mathbf{y}^T \\mathbf{Xw} = \\mathbf{(Xw)}^T \\mathbf{y}$\n",
    "\n",
    "Now that we know this we can write the expression\n",
    "\n",
    "$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{y}^T \\mathbf{y} - 2\\mathbf{y}^T \\mathbf{Xw} + \\mathbf{(Xw)}^T \\mathbf{Xw} + a \\,\\mathbf{w^Tw})$\n",
    "\n",
    "that we can derivate to get an expression we can use for gradient decent\n",
    "\n",
    "$\\frac{dL}{dw} = \\frac{1}{N}(2\\mathbf{y^TX} - 2\\mathbf{X^TXw^*} + 2a \\,\\mathbf{w^*} )$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### c) Derive optimal solution [2 points]\n",
    "Derive and write down in matrix/vector forms the solution $\\mathbf{w}^*$ to the optimization problem $\\min_{\\mathbf{w}}  \\mathcal{L}(\\mathbf{w})$. Show all your derivations. (Hint: $\\mathcal{L}(\\mathbf{w})$ is convex in $\\mathbf{w}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here:\n",
    "\n",
    "#### Step 1: Find the derivative $\\frac{dL}{dw}$ and evaluate it for solutions equal to zero. \n",
    "$\\frac{dL}{dw} = \\frac{1}{N}(2\\mathbf{y^TX} - 2\\mathbf{X^TXw^*} + 2a \\,\\mathbf{w^*} ) = 0$.\n",
    "\n",
    "This becomes after some simplifications:\n",
    "\n",
    "$\\mathbf{w^*} = (\\mathbf{X^TX} - 2a\\mathbf{I})^{-1}(\\mathbf{y^TX})$, where $I \\in \\mathbb{R}^{p \\times p }.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Uniqueness of solution [2 points]\n",
    "Under which condition on the $\\alpha$ is the solution $\\mathbf{w}^*$ unique? Prove rigorously your statement. Make no assumptions on $\\mathbf{X}$. (Hint: If your solution $\\mathbf{w}^*$ requires to invert a matrix, then one necessary condition for uniqueness is for the matrix to be invertible. And any positive definitive matrix https://en.wikipedia.org/wiki/Definiteness_of_a_matrix is invertible. You might also want to look at the properties of transposition https://en.wikipedia.org/wiki/Transpose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here:\n",
    "\n",
    "For $\\mathbf{w^*}$ to be a unique solution we must show that the equation of the form of a linear system \n",
    "\n",
    "$ \\mathbf{Ax} = \\mathbf{b}$  \n",
    "\n",
    "has an invertible matrix $\\mathbf{A}$ such that $\\mathbf{x}$ is the unique solution for $\\mathbf{x} = \\mathbf{A^{-1}b}$\n",
    "\n",
    "If we apply this to \n",
    "\n",
    "$\\mathbf{w^*} = (\\mathbf{X^TX} - 2\\alpha\\mathbf{I})^{-1}(\\mathbf{y^TX})$\n",
    "\n",
    "it equates to proving that $\\mathbf{X^TX} - 2\\alpha\\mathbf{I}$ is invertible for some condition on $\\alpha$. We know that a sqare matrix is invertible if and only if it has  nonzero eigenvalues. We also know that $\\mathbf{X^TX} -2\\alpha\\mathbf{I}$ is symetric and a symetric matrix is positive definite if and oly if all its eigenvalues are strictly positive. \n",
    "\n",
    "The definition of a eigenvalue is $A\\mathbf{v} = \\lambda \\mathbf{v}$. If we call the eigenvalues for $\\mathbf{X^TX}$ for $\\lambda_i$ then $\\mathbf{X^TX} \\mathbf{v} = \\lambda_i \\mathbf{v}$. \n",
    "\n",
    "If we apply our matrix $(\\mathbf{X^TX} - 2\\alpha\\mathbf{I}) $ to $\\mathbf{v}$ we get $(\\mathbf{X^TX} - 2\\alpha\\mathbf{I})\\mathbf{v} = (\\mathbf{X^TX}\\mathbf{v} - 2\\alpha\\mathbf{I}\\mathbf{v}) = \\lambda_i \\mathbf{v} - 2\\alpha\\mathbf{v}$ since $\\mathbf{I}\\mathbf{v} = \\mathbf{v}$. \n",
    "\n",
    "If we factor out $\\mathbf{v}$ we get \n",
    "\n",
    "$(\\mathbf{X^TX} - 2\\alpha\\mathbf{I})\\mathbf{v} = (\\lambda_{min} - 2\\alpha)\\mathbf{v}$\n",
    "where $\\lambda_{min}$ is the smallest eigenvalue of $\\mathbf{X^TX}$\n",
    "\n",
    "This shows that the eigenvalues for $(\\mathbf{X^TX} - 2\\alpha\\mathbf{I}) $ is $(\\lambda_{min} - 2\\alpha)$\n",
    "\n",
    "The condition on the eigenvalues of $(\\mathbf{X^TX} - 2\\alpha\\mathbf{I}) $ was that they were positive which gives the condition $(\\lambda_{min} - 2\\alpha) > 0$ which simplifies to $\\alpha < \\frac{\\lambda_{min}}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### e) Implement linear model fitting [2 points]\n",
    "In the code block below, implement a well commented function `fit_linear_with_regularization` that takes as input $\\mathbf{X}$, $\\mathbf{y}$ and $\\alpha$ and return $\\mathbf{w}^*$ as computed in question 3. You are not allowed to use any loops (for-loop, while-loop ...) to do the implementation. Instead you must use numpy operations as much as possible. \n",
    "\n",
    "Fill in the `TODO` sections in the `fit_linear_with_regularization` function below.\n",
    "\n",
    "### f) Implement linear model prediction [3 points]\n",
    "In the code block below, implement a well commented function `predict` that takes as input a dataset $\\mathbf{X_{\\text{test}}}$ in the same dimensions as $\\mathbf{X}$ and return the predictions.   Write down the mean squared error (https://en.wikipedia.org/wiki/Mean_squared_error) of your predictions. Then on the same plot with legends, show:\n",
    "\n",
    " a) A scatter plot of the first feature of $\\mathbf{X_{\\text{test}}}$ (x-axis) and the diabetes progression $\\mathbf{y_{\\text{test}}}$ \n",
    " \n",
    " b) A plot of your prediction for $\\mathbf{X_{\\text{test}}}$\n",
    " \n",
    " The skeleton code in the cell below already implements most of data loading and you should only have to fill in the `TODO` sections. Again here no loops are allowed (for-loop, while loop in the implementation of the plots and the **predict** )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2010.2186\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make it possible to show plots in the notebook.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "def fit_linear_with_regularization(X, y, alpha):\n",
    "    \"\"\"\n",
    "    Fits a linear model with regularization (ridge regression).\n",
    "    \"\"\"\n",
    "    onesCol = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((onesCol, X))\n",
    "    nrOfCols = X.shape[1]  # Number of columns (features)\n",
    "    \n",
    "    # Compute ridge regression solution: (X^T X + ŒªI)^(-1) X^T y\n",
    "    first = np.matmul(X.T, X) + 2 * alpha * np.eye(nrOfCols)  # Regularized term\n",
    "    invFirst = np.linalg.inv(first)  # Compute inverse\n",
    "    second = np.matmul(X.T, y)  # Compute X^T y\n",
    "    omegaStar = np.matmul(invFirst, second)  # Compute w (coefficients)\n",
    "    \n",
    "    return omegaStar\n",
    "\n",
    "def predict(X_test, w):\n",
    "    \"\"\"\n",
    "    Computes predictions using the learned weights.\n",
    "    \"\"\"\n",
    "    onesCol = np.ones((X_test.shape[0], 1))\n",
    "    X_test = np.hstack((onesCol, X_test))\n",
    "    return np.dot(X_test, w)  # Linear model: y_pred = X_test * w\n",
    "\n",
    "def plot_prediction(X_test, y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Plots actual vs. predicted values and computes mean squared error.\n",
    "    \"\"\"\n",
    "    onesCol = np.ones((X_test.shape[0], 1))\n",
    "    X_test = np.hstack((onesCol, X_test))\n",
    "    firstFeatureX = X_test[:, 0]  # Extract first feature of X_test\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(firstFeatureX, y_test, label=\"Actual Data\", color=\"blue\", alpha=0.6)\n",
    "    plt.scatter(firstFeatureX, y_pred, label=\"Predicted Data\", color=\"red\", alpha=0.6)\n",
    "    plt.xlabel(\"First Feature of Patients\")\n",
    "    plt.ylabel(\"Diabetes Progression\")\n",
    "    plt.title(\"Actual vs Predicted Diabetes Progression\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Compute mean squared error\n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# Load the diabetes dataset\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Split the dataset into training and test set\n",
    "num_test_elements = 20\n",
    "X_train, X_test = X[:-num_test_elements], X[-num_test_elements:]\n",
    "y_train, y_test = y[:-num_test_elements], y[-num_test_elements:]\n",
    "\n",
    "# Set regularization parameter\n",
    "alpha = 0.01\n",
    "\n",
    "# Train the model\n",
    "w = fit_linear_with_regularization(X_train, y_train, alpha)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict(X_test, w)\n",
    "\n",
    "# Plot results and compute mean squared error\n",
    "mse = plot_prediction(X_test, y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus problem\n",
    "Answering this question will not give you any additional points. Not answering this question will not prevent you from getting full points (if all other questions are answered correctly). However, if you answer this question, we will pick exactly one question where you didn't receive full points in this assignment and give you **at most** 4 more points there. In particular, between the questions for which you have reasonably attempted a solution, we will pick the one where the difference between the full point and the point you received is the maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Bayesian Linear Regression [up to 4 bonus points]\n",
    "\n",
    "Proud of finishing the task using a linear model with regularization, you show your results to a representative of the Swedish Public Health Agency. You barely finish explaining your solution when the face of the representative turns red and you could distinctly hear: \"Bayesian is the only way: How come didn't you use any probabilities?\". \n",
    "\n",
    "You quickly head back to your desk and now assume a Gaussian prior on the solution $\\mathbf{w}$, that is $p(\\mathbf{w}) = \\mathcal{N}(\\mathbf{0}, \\lambda^{-1} \\mathbf{I})$ where $\\lambda \\in \\mathbb{R}$ is a constant real number, $I$ is the $p \\times p$ identity matrix and $\\mathcal{N}(\\mathbf{0}, \\lambda^{-1} \\mathbf{I})$ is used to mean the multivariate gaussian distribution with mean $\\mathbf{0} \\in \\mathbb{R}^p$ , a vector of zeros of dimension $p$ and covariance matrix $\\lambda^{-1} \\mathbf{I}$ . Then, you use the following likelihood:\n",
    "\n",
    "$$p(\\mathbf{y} | \\mathbf{X}, \\mathbf{w}) = \\prod_{i=1}^n \\mathcal{N}(\\mathbf{w}^T \\mathbf{x}_i, \\gamma^{-1})$$\n",
    "\n",
    "where $\\gamma \\in \\mathbb{R}$ is a constant real number and $\\mathcal{N}(\\mathbf{w}^T \\mathbf{x}_i, \\gamma^{-1})$ is the Gaussian distribution with mean  $\\mathbf{w}^T \\mathbf{x}_i$ and variance $\\gamma^{-1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### a) Derive log posterior [2 points]\n",
    "Derive an expression for the log posterior $\\ln p(\\mathbf{w} | \\mathbf{y}, \\mathbf{X})$ in vector/matrix form as a function of $\\mathbf{X}, \\mathbf{y}, \\mathbf{w}$. Show all derivations. You can ignore normalizing constants.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b) Equivalence of Bayesian and regularized regression [2 points]\n",
    "Show that maximizing the posterior in a) is  similar to minimizing the function $\\mathcal{L}(\\mathbf{w})$ seen in the previous section. Show your derivations. (Note: You should show this without computing the maximum of the posterior. Instead, you should express the log posterior in term of $\\mathcal{L}(\\mathbf{w})$, ignoring constants if necessary. Then find the $\\alpha$ of $\\mathcal{L}(\\mathbf{w})$ in term of $\\lambda$ and $\\gamma$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìù Your answer here:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Hw1_2019.ipynb",
   "provenance": [
    {
     "file_id": "1Y5XjPfo2fv3nGBtIxbf0F_WFtssz1N_S",
     "timestamp": 1553254350644
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
